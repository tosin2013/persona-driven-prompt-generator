# LiteLLM Configuration Examples
# Choose ONE provider and configure its variables accordingly

# OpenAI Configuration
# export LITELLM_MODEL="gpt-3.5-turbo"
# export LITELLM_PROVIDER="openai"
# export OPENAI_API_KEY="your-openai-api-key"

# Groq Configuration
# export LITELLM_MODEL="groq/mixtral-8x7b-32768"
# export LITELLM_PROVIDER="groq"
# export GROQ_API_KEY="your-groq-api-key"

# DeepSeek Configuration
# export LITELLM_MODEL="deepseek-model-name"
# export LITELLM_PROVIDER="deepseek"
# export DEEPSEEK_API_KEY="your-deepseek-api-key"

# Hugging Face Configuration
# export LITELLM_MODEL="huggingface/transformer-model"
# export LITELLM_PROVIDER="huggingface"
# export HUGGINGFACE_API_KEY="your-huggingface-api-key"

# Ollama Configuration
# export LITELLM_MODEL="ollama/llama2"
# export LITELLM_PROVIDER="ollama"
# export LITELLM_API_BASE="http://localhost:11434"
# export OLLAMA_API_KEY="your-ollama-api-key"

# Note: Uncomment and configure only ONE provider's settings.
# Replace placeholder values with your actual API keys and model names.
