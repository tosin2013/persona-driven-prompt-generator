# LiteLLM Configuration Guide
# This application uses LiteLLM (https://github.com/BerriAI/litellm) to support multiple LLM providers
# Choose ONE provider configuration below and rename this file to .env

# ===== Available Provider Configurations =====

# 1. OpenAI Configuration (GPT-3.5, GPT-4)
# Best for: General purpose, high-quality responses
LITELLM_MODEL=gpt-3.5-turbo
LITELLM_PROVIDER=openai
OPENAI_API_KEY=your-openai-api-key

# 2. Groq Configuration (Mixtral, Llama)
# Best for: Fast inference, competitive pricing
# LITELLM_MODEL=groq/mixtral-8x7b-32768
# LITELLM_PROVIDER=groq
# GROQ_API_KEY=your-groq-api-key

# 3. DeepSeek Configuration
# Best for: Specialized tasks, research applications
# LITELLM_MODEL=deepseek-model-name
# LITELLM_PROVIDER=deepseek
# DEEPSEEK_API_KEY=your-deepseek-api-key

# 4. Hugging Face Configuration
# Best for: Custom models, open-source alternatives
# LITELLM_MODEL=huggingface/transformer-model
# LITELLM_PROVIDER=huggingface
# HUGGINGFACE_API_KEY=your-huggingface-api-key

# 5. Ollama Configuration (Local Deployment)
# Best for: Self-hosted, privacy-focused applications
# LITELLM_MODEL=ollama/llama2
# LITELLM_PROVIDER=ollama
# LITELLM_API_BASE=http://localhost:11434
# OLLAMA_API_KEY=your-ollama-api-key

# ===== Additional Configuration =====

# Database Configuration (Optional)
# Uncomment if using database features
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=your_database_name
# DB_USER=your_database_user
# DB_PASSWORD=your_database_password

# Application Settings
DEBUG=false
LOG_LEVEL=INFO

# Instructions:
# 1. Copy this file to .env: cp env-example .env
# 2. Uncomment and configure ONE provider section
# 3. Replace placeholder values with actual credentials
# 4. Configure additional settings as needed
