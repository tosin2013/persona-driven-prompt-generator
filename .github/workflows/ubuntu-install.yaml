name: Deploy to DigitalOcean Droplet

on:
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}

      - name: Create Droplet
        id: create_droplet
        run: |
          DROPLET_IP=$(doctl compute droplet create "ubuntu-s-2vcpu-4gb-amd-sfo3-github" \
            --region sfo3 \
            --image ubuntu-22-04-x64 \
            --size s-2vcpu-4gb-amd \
            --ssh-keys $(doctl compute ssh-key list --format ID --no-header) \
            --vpc-uuid ${{ secrets.DIGITALOCEAN_VPC }} \
            --wait \
            --format PublicIPv4 \
            --no-header)
          echo "DROPLET_IP=$DROPLET_IP" >> $GITHUB_ENV

      - name: Output Droplet IP
        run: "echo Droplet IP: ${{ env.DROPLET_IP }}"
        continue-on-error:  false

      - name: Wait for SSH
        timeout-minutes: 5
        run: |
          until ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \
            -i <(echo "${{ secrets.DROPLET_SSH_KEY }}") \
            root@${{ env.DROPLET_IP }} echo "SSH ready"; do
            sleep 10
          done

      - name: Deploy Application
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ env.DROPLET_IP }}
          username: root
          key: ${{ secrets.DROPLET_SSH_KEY }}
          script: |
            #!/bin/bash
            set -e

            # Update system
            apt-get update && apt-get upgrade -y
            apt-get install -y python3-pip git ufw coreutils

            # Configure firewall
            ufw allow 22/tcp
            ufw allow 8501/tcp
            yes | ufw enable

            # Install Ollama
            curl -fsSL https://ollama.com/install.sh | sh

            # Clone and setup application
            git clone https://github.com/tosin2013/persona-driven-prompt-generator.git
            cd persona-driven-prompt-generator
            pip3 install -r requirements.txt
            bash setup_database.sh -i

            # Configure environment
            cat > /etc/environment <<EOF
            LITELLM_MODEL="ollama/llama2"
            LITELLM_PROVIDER="ollama"
            LITELLM_API_BASE="http://localhost:11434"
            OLLAMA_API_KEY="${{ secrets.OLLAMA_API_KEY }}"
            EOF
            source /etc/environment

            # Pull Ollama model
            ollama pull $LITELLM_MODEL

            # Setup systemd service
            cat > /etc/systemd/system/streamlit.service <<EOF
            [Unit]
            Description=Streamlit Application
            After=network.target

            [Service]
            Environment=LITELLM_MODEL=ollama/llama2
            Environment=LITELLM_PROVIDER=ollama
            Environment=LITELLM_API_BASE=http://localhost:11434
            Environment=OLLAMA_API_KEY=${{ secrets.OLLAMA_API_KEY }}
            ExecStart=/usr/local/bin/streamlit run /root/persona-driven-prompt-generator/persona_testing.py
            Restart=always
            User=root

            [Install]
            WantedBy=multi-user.target
            EOF

            systemctl daemon-reload
            systemctl enable streamlit
            systemctl start streamlit

      - name: Output Droplet IP
        run: echo "Application deployed at http://${{ env.DROPLET_IP }}:8501"
